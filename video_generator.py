import openai
import requests
import deepl
from moviepy.editor import *
import os
from dotenv import load_dotenv
import math
from PIL import Image
import io
from moviepy.config import change_settings
from gtts import gTTS
from pytrends.request import TrendReq
import datetime
import logging

# Configuration de MoviePy
change_settings({"IMAGEMAGICK_BINARY": r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe"})

# Chargement des variables d'environnement
load_dotenv()

# Configuration des cl√©s API
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PEXELS_API_KEY = "0Nd2ZIJSJHGRp1x4cBwauCPuCIH08CexznNpsuAw1sIbTaLH4wHRMN3d"
DEEPL_API_KEY = os.getenv("DEEPL_API_KEY")

class VideoGenerator:
    def __init__(self):
        # Configuration la plus simple possible du client OpenAI
        self.client = openai.OpenAI(
            api_key=OPENAI_API_KEY
        )
        
        self.topics = {
            "science": "Les exoplan√®tes habitables d√©couvertes en 2024",
            "crypto": "L'impact des ETF Bitcoin sur le march√© crypto",
            "ai": "Les derni√®res avanc√©es de l'IA g√©n√©rative multimodale"
        }

    def generate_script(self, topic_type):
        """G√©n√®re un script pour la vid√©o"""
        try:
            prompt = f"""√âcris un script captivant pour TikTok sur : 
            {self.topics[topic_type]}. 

            R√®gles importantes:
            - √âcris UNIQUEMENT le texte √† dire, sans indications sc√©niques
            - Pas de "Texte √† l'√©cran", "Intervenant :", "(excit√©)", etc.
            - Pas de formatage ou de mise en page sp√©ciale
            
            Structure:
            - Une introduction accrocheuse (2-3 phrases)
            - 3-4 points principaux avec des d√©tails int√©ressants
            - Une conclusion avec call-to-action

            Le script doit √™tre en anglais, avoir un ton dynamique et durer environ 45-60 secondes.
            Utilise un langage simple et direct, avec des phrases courtes pour faciliter la lecture des sous-titres."""
            
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "Tu es un expert en cr√©ation de contenu viral pour TikTok. G√©n√®re uniquement le texte √† dire, sans indications de mise en sc√®ne ou formatage."},
                    {"role": "user", "content": prompt}
                ]
            )
            script = response.choices[0].message.content
            print(f"\n--- Script g√©n√©r√© pour {topic_type} ---\n{script}\n")
            return script
            
        except openai.AuthenticationError:
            print("‚ùå Erreur d'authentification OpenAI - V√©rifiez votre cl√© API")
            return None
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration du script: {str(e)}")
            return None

    def text_to_speech(self, text, output_path):
        """Convertit le texte en voix avec Google TTS"""
        try:
            # Cr√©ation de l'objet gTTS
            tts = gTTS(text=text, lang='en', slow=False)
            
            # Sauvegarde du fichier audio
            tts.save(output_path)
            print(f"‚úÖ Audio g√©n√©r√© avec succ√®s: {output_path}")
            return True
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration audio: {str(e)}")
            return False

    def get_image(self, keyword, output_path):
        """R√©cup√®re une image depuis Unsplash"""
        url = f"https://api.unsplash.com/photos/random?query={keyword}&client_id={UNSPLASH_ACCESS_KEY}"
        response = requests.get(url).json()
        img_url = response["urls"]["regular"]

        img_data = requests.get(img_url).content
        with open(output_path, "wb") as f:
            f.write(img_data)

    def get_multiple_images(self, keyword, count, output_dir):
        """R√©cup√®re plusieurs images depuis Pexels et les formate pour TikTok"""
        images = []
        try:
            headers = {"Authorization": PEXELS_API_KEY}
            url = f"https://api.pexels.com/v1/search?query={keyword}&orientation=portrait&per_page={count}"
            response = requests.get(url, headers=headers)
            
            if response.status_code != 200:
                print(f"‚ùå Erreur API Pexels: {response.status_code}")
                return []
                
            data = response.json()
            for i, photo in enumerate(data["photos"][:count]):
                img_url = photo["src"]["large2x"]  # Haute qualit√©
                output_path = f"{output_dir}/image_{keyword}_{i+1}.jpg"
                
                # T√©l√©chargement et redimensionnement
                img_response = requests.get(img_url)
                if img_response.status_code == 200:
                    img = Image.open(io.BytesIO(img_response.content))
                    
                    # Format TikTok
                    target_width = 1080
                    target_height = 1920
                    
                    # Redimensionnement avec ratio
                    img_ratio = img.width / img.height
                    target_ratio = target_width / target_height
                    
                    if img_ratio > target_ratio:
                        new_width = int(target_height * img_ratio)
                        new_height = target_height
                        img = img.resize((new_width, new_height))
                        left = (new_width - target_width) // 2
                        img = img.crop((left, 0, left + target_width, target_height))
                    else:
                        new_width = target_width
                        new_height = int(target_width / img_ratio)
                        img = img.resize((new_width, new_height))
                        top = (new_height - target_height) // 2
                        img = img.crop((0, top, target_width, top + target_height))
                    
                    img.save(output_path, quality=95)
                    images.append(output_path)
                    print(f"‚úÖ Image {i+1} pour '{keyword}' t√©l√©charg√©e et format√©e (1080x1920)")
            
            return images
            
        except Exception as e:
            print(f"‚ùå Erreur lors du t√©l√©chargement des images: {str(e)}")
            return []

    def split_into_subtitles(self, text, max_chars=50):
        """D√©coupe le texte en sous-titres courts bas√©s sur le nombre de caract√®res"""
        sentences = text.split('.')
        subtitles = []
        
        current_subtitle = ""
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # Si la phrase est tr√®s courte, on l'ajoute directement
            if len(sentence) <= max_chars:
                subtitles.append(sentence)
                continue
            
            # Sinon, on d√©coupe en morceaux logiques
            words = sentence.split()
            current_part = []
            
            for word in words:
                current_part.append(word)
                current_text = ' '.join(current_part)
                
                # Si on d√©passe la limite ou si on a une ponctuation naturelle
                if len(current_text) >= max_chars or any(p in word for p in [',', '!', '?', ';']):
                    subtitles.append(current_text)
                    current_part = []
                
            # Ajouter les mots restants
            if current_part:
                subtitles.append(' '.join(current_part))
        
        return subtitles

    def create_video(self, images_dir, audio_path, output_path):
        """Cr√©e la vid√©o finale avec sous-titres"""
        try:
            # Chargement de l'audio
            audio = AudioFileClip(audio_path)
            
            # R√©cup√©ration des images
            image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg')])
            if not image_files:
                raise Exception("Aucune image trouv√©e dans le dossier")
            
            # Cr√©ation des clips d'images
            image_clips = []
            duration_per_image = 4.0
            current_time = 0
            
            for img_file in image_files:
                img_path = os.path.join(images_dir, img_file)
                img_clip = (ImageClip(img_path)
                           .set_duration(duration_per_image)
                           .set_start(current_time))
                image_clips.append(img_clip)
                current_time += duration_per_image
            
            # Cr√©ation de la vid√©o de base
            video = concatenate_videoclips(image_clips).set_audio(audio)
            
            # Chargement et d√©coupage des sous-titres
            with open('test/traductions/science_fr.txt', 'r', encoding='utf-8') as f:
                text = f.read()
            subtitles = self.split_into_subtitles(text)
            
            # Calcul intelligent du timing des sous-titres
            total_duration = audio.duration
            avg_reading_time = 0.4  # Augment√© √† 400ms par mot
            min_duration = 2.0      # Dur√©e minimum augment√©e √† 2 secondes
            
            subtitle_clips = []
            current_time = 0
            
            for subtitle in subtitles:
                # Calcul de la dur√©e bas√©e sur le nombre de mots et caract√®res
                words_count = len(subtitle.split())
                chars_count = len(subtitle)
                
                # Dur√©e calcul√©e en fonction des mots ET des caract√®res
                word_duration = words_count * avg_reading_time
                char_duration = chars_count * 0.05  # 50ms par caract√®re
                
                # On prend la plus grande des deux dur√©es
                duration = max(word_duration, char_duration, min_duration)
                
                # Ajout d'une pause entre les phrases
                if subtitle.strip().endswith(('.', '!', '?')):
                    duration += 0.5  # Pause de 0.5 seconde apr√®s chaque phrase
                
                # Ajustement pour ne pas d√©passer la dur√©e totale
                if current_time + duration > total_duration:
                    duration = total_duration - current_time
                
                if duration <= 0:  # Skip si plus de temps disponible
                    break
                
                txt_clip = (TextClip(subtitle,
                                   fontsize=90,
                                   color='white',
                                   bg_color='rgba(0,0,0,0.8)',
                                   font='Arial-Bold',
                                   size=(video.w * 0.95, None),
                                   method='caption',
                                   stroke_color='black',
                                   stroke_width=3)
                           .set_start(current_time)
                           .set_duration(duration)
                           .set_pos(('center', 'bottom')))
                
                subtitle_clips.append(txt_clip)
                current_time += duration
            
            # Assemblage final
            final = CompositeVideoClip([video] + subtitle_clips)
            final.write_videofile(output_path, fps=24, codec='libx264', audio_codec='aac')
            print(f"‚úÖ Vid√©o g√©n√©r√©e avec succ√®s: {output_path}")
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la cr√©ation de la vid√©o: {str(e)}")

    def get_subtitles(self, audio_path):
        """G√©n√®re et traduit les sous-titres"""
        # Temporairement, on retourne un texte fixe pour tester
        text = "This is a placeholder for the transcribed text"
        
        translator = deepl.Translator(DEEPL_API_KEY)
        return translator.translate_text(text, target_lang="FR").text

    def generate_all_videos(self):
        """G√©n√®re les 3 vid√©os"""
        for topic in self.topics:
            print(f"G√©n√©ration de la vid√©o sur {topic}...")
            
            # Cr√©ation des chemins de fichiers
            base_path = f"output/{topic}"
            os.makedirs(base_path, exist_ok=True)
            
            # G√©n√©ration du contenu
            script = self.generate_script(topic)
            self.text_to_speech(script, f"{base_path}/audio.mp3")
            self.get_image(topic, f"{base_path}/image.jpg")
            self.create_video(
                f"{base_path}/image.jpg",
                f"{base_path}/audio.mp3",
                f"{base_path}/final.mp4"
            )
            print(f"Vid√©o {topic} g√©n√©r√©e avec succ√®s!")

    def test_script_generation(self):
        """Teste la g√©n√©ration de scripts pour tous les topics"""
        print("üöÄ Test de g√©n√©ration des scripts...")
        
        for topic in self.topics:
            print(f"\nüìù G√©n√©ration pour le topic: {topic}")
            script = self.generate_script(topic)
            if script:
                print("‚úÖ G√©n√©ration r√©ussie!")
            else:
                print("‚ùå √âchec de la g√©n√©ration")

    def test_translation(self):
        """Teste la traduction avec DeepL"""
        print("\nüåç Test de traduction DeepL...")
        
        test_text = "Discover the fascinating world of exoplanets! Scientists have recently found three Earth-like planets that could potentially harbor life."
        
        try:
            translator = deepl.Translator(DEEPL_API_KEY)
            translated = translator.translate_text(test_text, target_lang="FR")
            print("\n‚ú® Texte original:")
            print(test_text)
            print("\n‚ú® Traduction:")
            print(translated.text)
            print("\n‚úÖ Test de traduction r√©ussi!")
            return True
            
        except deepl.exceptions.AuthenticationException:
            print("‚ùå Erreur d'authentification DeepL - V√©rifiez votre cl√© API")
            return False
        except Exception as e:
            print(f"‚ùå Erreur lors de la traduction: {str(e)}")
            return False

    def test_subtitles_split(self):
        """Teste le d√©coupage des sous-titres"""
        print("\nüìù Test de d√©coupage des sous-titres...")
        
        test_text = "D√©couvrez le monde fascinant des exoplan√®tes ! Les scientifiques ont r√©cemment d√©couvert trois plan√®tes semblables √† la Terre qui pourraient potentiellement abriter la vie."
        
        subtitles = self.split_into_subtitles(test_text)
        print("\n‚ú® Sous-titres d√©coup√©s:")
        for idx, subtitle in enumerate(subtitles, 1):
            print(f"{idx}. {subtitle}")
        
        return True

    def test_science_content(self):
        """Teste la g√©n√©ration compl√®te pour le topic science"""
        test_dirs = ['test/textes', 'test/traductions', 'test/sous-titres', 'test/images', 'test/audio']
        for dir_path in test_dirs:
            os.makedirs(dir_path, exist_ok=True)

        try:
            # 1. G√©n√©ration du texte en anglais
            print("\nüìù G√©n√©ration du script en anglais...")
            script = self.generate_script("science")
            
            # Sauvegarde du texte anglais
            with open('test/textes/science_en.txt', 'w', encoding='utf-8') as f:
                f.write(script)
            print("‚úÖ Texte anglais sauvegard√©")

            # 2. Traduction en fran√ßais
            print("\nüåç Traduction en fran√ßais...")
            translator = deepl.Translator(DEEPL_API_KEY)
            translated = translator.translate_text(script, target_lang="FR")
            
            with open('test/traductions/science_fr.txt', 'w', encoding='utf-8') as f:
                f.write(translated.text)
            print("‚úÖ Traduction sauvegard√©e")

            # 3. G√©n√©ration de l'audio
            print("\nüé§ G√©n√©ration de l'audio...")
            audio_path = 'test/audio/test_josh.mp3'
            self.text_to_speech(script, audio_path)
            
            # Calcul du nombre d'images n√©cessaires bas√© sur la dur√©e de l'audio
            audio = AudioFileClip(audio_path)
            images_needed = math.ceil(audio.duration / 4)  # Une image toutes les 4 secondes
            
            # 4. R√©cup√©ration des images
            print(f"\nüì∏ T√©l√©chargement de {images_needed} images...")
            search_terms = ["exoplanet", "space telescope", "habitable planet", "star system"]
            all_images = []
            images_per_term = math.ceil(images_needed / len(search_terms))
            
            for term in search_terms:
                images = self.get_multiple_images(term, images_per_term, 'test/images')
                if images:
                    all_images.extend(images)

            # 5. G√©n√©ration des sous-titres avec timing adapt√© aux images
            print("\nüé¨ G√©n√©ration des sous-titres...")
            subtitles = self.split_into_subtitles(translated.text)
            
            # Calcul du nombre d'images n√©cessaires
            total_duration = len(subtitles) * 2.5  # 2.5 secondes par sous-titre
            images_needed = math.ceil(total_duration / 4)  # Une image toutes les 4 secondes
            
            # Sauvegarde des sous-titres au format SRT avec timing des images
            with open('test/sous-titres/science.srt', 'w', encoding='utf-8') as f:
                for idx, subtitle in enumerate(subtitles, 1):
                    start_time = self.format_timecode(idx-1, 2.5)
                    end_time = self.format_timecode(idx, 2.5)
                    
                    # Ajout d'un marqueur pour le changement d'image
                    image_change = (idx-1) * 2.5 % 4 == 0
                    if image_change:
                        f.write(f"# IMAGE_CHANGE: {idx//2}\n")
                    
                    f.write(f"{idx}\n")
                    f.write(f"{start_time} --> {end_time}\n")
                    f.write(f"{subtitle}\n\n")
            
            print(f"‚úÖ Sous-titres sauvegard√©s (n√©cessite {images_needed} images)")
            print(f"‚úÖ {len(all_images)} images t√©l√©charg√©es")

            return True

        except Exception as e:
            print(f"‚ùå Erreur lors du test: {str(e)}")
            return False

    def format_timecode(self, index, duration_per_subtitle):
        """Convertit un index en timecode SRT"""
        total_seconds = index * duration_per_subtitle
        hours = int(total_seconds // 3600)
        minutes = int((total_seconds % 3600) // 60)
        seconds = int(total_seconds % 60)
        milliseconds = int((total_seconds * 1000) % 1000)
        
        return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"

    def test_voice_generation(self):
        """Teste la g√©n√©ration de voix avec Google TTS"""
        print("\nüé§ Test de g√©n√©ration de voix...")
        
        try:
            # Cr√©ation du dossier de test pour l'audio
            os.makedirs('test/audio', exist_ok=True)
            
            # Utiliser le texte anglais existant s'il existe
            if os.path.exists('test/textes/science_en.txt'):
                with open('test/textes/science_en.txt', 'r', encoding='utf-8') as f:
                    text = f.read()
            else:
                text = "Hey there! Today we're exploring the fascinating world of exoplanets. Scientists have made incredible discoveries in 2024!"
            
            print("\nüìù Texte √† convertir:")
            print(text[:100] + "..." if len(text) > 100 else text)
            
            output_path = 'test/audio/test_josh.mp3'
            return self.text_to_speech(text, output_path)
                
        except Exception as e:
            print(f"‚ùå Erreur lors du test de voix: {str(e)}")
            return False

    def get_trending_topics(self):
        """R√©cup√®re les sujets tendances"""
        try:
            logging.info("Tentative de r√©cup√©ration des tendances...")
            # Configuration de Google Trends
            pytrends = TrendReq(hl='en-US', tz=360)
            
            # Dictionnaire pour stocker les r√©sultats
            trending_topics = {
                "science": [],
                "crypto": [],
                "ai": []
            }
            
            # Mots-cl√©s de recherche par cat√©gorie
            search_queries = {
                "science": ["space discovery", "scientific breakthrough", "new planet", "NASA"],
                "crypto": ["bitcoin", "ethereum", "cryptocurrency", "blockchain"],
                "ai": ["artificial intelligence", "machine learning", "ChatGPT", "AI"]
            }
            
            for category, queries in search_queries.items():
                print(f"\nüîç Recherche des tendances pour {category}...")
                
                # Utilisation de interest_over_time au lieu de trending_searches
                pytrends.build_payload(queries, timeframe='now 7-d')
                trends_data = pytrends.interest_over_time()
                
                if not trends_data.empty:
                    # Calcul des moyennes pour chaque requ√™te
                    avg_trends = trends_data.mean().sort_values(ascending=False)
                    
                    # S√©lection des 3 termes les plus populaires
                    top_trends = avg_trends.head(3)
                    trending_topics[category] = [
                        f"{term} ({int(score)})" 
                        for term, score in top_trends.items()
                    ]
                    
                    print(f"‚úÖ Tendances trouv√©es pour {category}:")
                    for idx, trend in enumerate(trending_topics[category], 1):
                        print(f"  {idx}. {trend}")
                else:
                    print(f"‚ùå Aucune tendance trouv√©e pour {category}")
            
            # Mise √† jour des topics de la classe avec les tendances les plus populaires
            for category, trends in trending_topics.items():
                if trends:
                    top_trend = trends[0].split(' (')[0]  # Retire le score entre parenth√®ses
                    self.topics[category] = f"Les derni√®res d√©couvertes sur {top_trend}"
            
            logging.info(f"Tendances r√©cup√©r√©es avec succ√®s : {self.topics}")
            return trending_topics
            
        except Exception as e:
            logging.error(f"Erreur lors de la r√©cup√©ration des tendances : {str(e)}")
            return None 